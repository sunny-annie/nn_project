import torch
import json
import urllib.request, json
import streamlit as st
from torchvision.models import inception_v3, Inception_V3_Weights
from torchvision import transforms as T
from torchvision import io
from PIL import Image
from translatepy.translators.google import GoogleTranslate  
 
gtranslate = GoogleTranslate()  

with urllib.request.urlopen("https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json") as url:
    labels = json.load(url)
    
decode = lambda x: labels[str(x)][1]

model = inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)
model.eval()

st.write("""
## –ó–∞–≥—Ä—É–∑–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é, –∏ —è –æ–ø—Ä–µ–¥–µ–ª—é, —á—Ç–æ –Ω–∞ –Ω–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ üïµüèª‚Äç‚ôÇÔ∏è
""")

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ jpeg –∏–ª–∏ jpg...", type=["jpg", "jpeg"])
if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    transform = T.Compose([
        T.Resize(256),
        T.CenterCrop(224),
        T.ToTensor(),
        T.Normalize(
            mean=[0.5, 0.5, 0.5],
            std=[0.5, 0.5, 0.5]
        )
    ])
    image_tensor = transform(image).unsqueeze(0)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output[0], dim=0)
        top_probabilities, top_classes = torch.topk(probabilities, k=3)
        top_classes = top_classes.tolist()

  

    st.write('–¢–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:')
    for i in range(3):
        st.write(f'{gtranslate.translate((decode(top_classes[i])).replace("_", " ").capitalize(), "Russian")}: {(top_probabilities[i]*100):.2f}%')
